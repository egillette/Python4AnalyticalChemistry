{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F and T tests in Python\n",
    "\n",
    "To compare your various indicator data, we need to process the data a little bit (to get averages and standard deviations, at least) and then you need to set up the F test and T-tests to then make a decision. But you already did this in Lab 1, so you can re-use all that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like we imported some extra math functions before, we're going to import some \n",
    "# extra math and statistical functions here\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# we need the average and standard deviation for each of our data sets. \n",
    "#Covert them into csv files and save them in the same folder as this notebook\n",
    "data = np.genfromtxt('SP20_exp3.csv', dtype=float, delimiter=',', names=True) \n",
    "\n",
    "#using the names = True in our import command has told python that all of our columns have names in the first row \n",
    "# and we can use those names to call the data!\n",
    "\n",
    "\n",
    "average_BB = np.nanmean(data['BB'])\n",
    "s_BB = np.nanstd(data['BB'])\n",
    "\n",
    "print (\"the average HCl concentration calculated using bromothymol blue is \" + str(average_BB) + \" +/- \" + str(s_BB) + \" M\")\n",
    "\n",
    "average_MR =  np.nanmean(data['MR'])\n",
    "s_MR = np.nanstd(data['MR'])\n",
    "\n",
    "print (\"the average HCl concentration calculated using methyl red is \" + str(average_MR) + \" +/- \" + str(s_MR) + \" M\")\n",
    "\n",
    "average_BG =  np.nanmean(data['BG'])\n",
    "s_BG = np.nanstd(data['BG'])\n",
    "\n",
    "print (\"the average HCl concentration calculated using Bromocresol Green is \" + str(average_BG) + \" +/- \" + str(s_BG) + \" M\")\n",
    "\n",
    "average_Ph =  np.nanmean(data['Ph'])\n",
    "s_Ph = np.nanstd(data['Ph'])\n",
    "\n",
    "print (\"the average HCl concentration calculated using Phenolphthalein is \" + str(average_Ph) + \" +/- \" + str(s_Ph) + \" M\")\n",
    "\n",
    "# We're just missing the last two indicators! \n",
    "# Fill in your own code to print out the average and standard deviation for thymolphthalein and methyl orange.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the output from above matches a calculation you did by hand.  \n",
    "\n",
    "We might also want 95 % confidence interval. We calculated this back in the very first Experiment 1 post-lab notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our data arrays are all different sizes, we have to make sure we remove any blank rows (with \"nan\" in them\n",
    "# from our calculation of the size.  You can use a similar statement to calculate n for each indicator.\n",
    "n = data.size - np.isnan(data['BB']).sum()\n",
    "\n",
    "#the first input is confidence %, the second is degrees of freedom (n-1)\n",
    "t = stats.t.ppf(0.95, n-1)\n",
    "\n",
    "CI_BB = s_BB*t/math.sqrt(n)\n",
    "\n",
    "print (\"[HCl] calculated using bromothymol blue is \" + str(average_BB) + \" +/- \" + str(CI_BB) + \" M, at the 95% confidence interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-test\n",
    "We want to know whether we can use all of the indicators interchangably. Are they all giving us essentially the same answer, or are some of the indicators producing results which are significantly different from the others? We will eventually want to know whether the means are the same, but there are many different ways to compare the means. First, we need to know if the standard deviations are similar, to help us decide which t-test to do!\n",
    "\n",
    "The F-test is a simple test:\n",
    "\n",
    "$$ F_{calculated} = (s_{1}^{2}/s_{2}^{2}) $$\n",
    "\n",
    "Note that $ s_{1} $ must be the larger standard deviation, so you should always have an F value greater than 1!  Let's start by comparing the two datasets that have the closest means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste in your F-test code from Lab 1.  Remember to add in a test to make sure that F_calc is > 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the F-test to choose a t-test\n",
    "Then we need to actually use our data to make a decision! This is where we use if-then statements to make a decision about how to proceed!\n",
    "\n",
    "We have two possible methods for calculating our t value.\n",
    "1. If the variance of the two data sets is the same, then we can use:\n",
    "\n",
    "$$ {\\displaystyle t_{calc}={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{s_{pooled}\\cdot {\\sqrt {{\\frac {1}{n_{1}}}+{\\frac {1}{n_{2}}}}}}}} $$\n",
    "\n",
    "where $$ s_{pooled} = {\\displaystyle s_{p}={\\sqrt {\\frac {\\left(n_{1}-1\\right)s_{{1}}^{2}+\\left(n_{2}-1\\right)s_{{2}}^{2}}{n_{1}+n_{2}-2}}}.} $$\n",
    "\n",
    "\n",
    "In this case, degrees of freedom is $ d.o.f = n_{1} + n_{2} -2 $\n",
    "\n",
    "2. If the variance of the two data sets is different, then we must use:\n",
    "$$ {\\displaystyle t={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{{\\sqrt {{\\frac {s_{1}^{2}}{n_{1}}}+{\\frac {s_{2}^{2}}{n_{2}}}}}}}} $$\n",
    "\n",
    "and the degrees of freedom equation is a little more complicated:\n",
    "\n",
    "$$ {\\displaystyle \\mathrm {d.o.f.} ={\\frac {\\left({\\frac {s_{1}^{2}}{n_{1}}}+{\\frac {s_{2}^{2}}{n_{2}}}\\right)^{2}}{{\\frac {\\left(s_{1}^{2}/n_{1}\\right)^{2}}{n_{1}-1}}+{\\frac {\\left(s_{2}^{2}/n_{2}\\right)^{2}}{n_{2}-1}}}}.} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste in your F-test IF statements and dof and t calculation code from Lab 1 here.  \n",
    "# Remember to add a test to make sure that t_calc is positive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the t-test to make a decision\n",
    "Now we have another decision to make, using that t_calc. If t_calc is greater thant t_critical, the means are not the same, and therefore the two indicators are NOT producing the same answer. We would not want to combine those data sets, or use those two indicators interchangably.\n",
    "\n",
    "\n",
    "To make this decisions, again, we'll use scipy to pull the right critical value. Then write your own if else statement to print out a statement about whether the two data sets have similar means or different means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste in your t-test code from Lab 1 here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this process for another pair of indicators! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Titration Data\n",
    "\n",
    "We will discuss how to get your data formatted to use it in these post-lab calculations!\n",
    "\n",
    "First, let's just take a look a the pH as a function of titrant added, and make sure our data has imported correctly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# This is how we'll import our data; it should be saved as a .csv file (but NOT UTF-8 csv), \n",
    "# in the same folder as this notebook. \n",
    "# Make sure you have volume in the first column and pH in the second column, with no headings on the data!\n",
    "\n",
    "csv = np.genfromtxt ('sample_titration.csv', delimiter=\",\")\n",
    "volume = csv[:,1]\n",
    "pH = csv[:,0]\n",
    "\n",
    "plt.plot(volume, pH, 'ro')\n",
    "\n",
    "# Add labels on the x and y axis, always including units.\n",
    "plt.xlabel('titrant added (mL)')\n",
    "plt.ylabel('pH')\n",
    "\n",
    "\n",
    "#let's just take a look!\n",
    "plt.show()\n",
    "      \n",
    "print(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding equivalence points\n",
    "\n",
    "Now, paste in your code from PythonLab 1 for taking the derivative of the titration curve data.  Note that the slope will be negative, so you may want to transform the data to positive numbers ... or use the np.argmin function to find the minimum for a negative peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the sharp peaks are at the equivalence points! Remember, a derivitive is just a measure of how quickly your function is changing, so it is largest where the slope of the line is largest. This makes the equivalence points a lot easier to see! \n",
    "Paste in your code from PythonLab 1 to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this endpoint match a visual inspection of the graph?  If so, record this endpoint volume in your ELN.  If not, check your raw data for a repeated reading (two identical points in a row).  If you find one, you can delete it in Excel and re-import, or use numpy's delete function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gran Plots\n",
    "\n",
    "Our second method for finding endpoints is the Gran plot. This works by highlighting the region near the equivalence point and zeroing in on the slope of the line as it approaches the endpoint. <b> It is helpful to already have an idea where your endpoint is, roughly, before you begin this section. </b>\n",
    "\n",
    "\n",
    "Gran plots can be helpful, because they take advantage of additional points leading up to the endpoint. Since the pH meter is least accurate near the endpoint, including these additional points in your calculation can help reduce some of the error coming from the sluggish kinetics of the pH meter itself.\n",
    "\n",
    "<b>Note that the Gran plot is done differently depending on whether you are titrating an acid or a base.</b>  When titrating a weak base with a strong acid (in other words, the strong acid is up in the burette), we need to graph volume x 10^pH vs volume.\n",
    "When titrating a weak acid with a strong base, we need to graph volume x 10^-pH vs volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and modify your Gran plot code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The endpoint is where this graph begins to approach zero, in the steepest part of the curve. To fit this to a line, ideally we would use a linear regression on the linear data just before the endpoint (in this case, what data should you choose?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and modify your code here from PythonLab 1 for trimming down the Gran plot data to the linear region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to get the most linear data close to the endpoint -- not including that last bit of curvature on the right.  Adjust the trim and start points to lose any curved data on either extreme of the plot.\n",
    "\n",
    "Once this is done, we want the x-intercept of this plot, which will be our first equivalence point!\n",
    "\n",
    "Remember, if $ y= mx +b $ we solve for the x-intercept by plugging in a zero for y, and solve for x. \n",
    "Rearranging, you'll get $$ x_{intercept} = \\frac{-b}{m} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the equation of the line\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "# The linear regression function in the scipy stats module returns 5 values: slope, intercept, R-squared and then \n",
    "# two uncertainty values p and s_m\n",
    "# We'll ignore the last two for the moment, since all we really need right now is the equation of the line\n",
    "m, b, R2, p, s_m = scipy.stats.linregress(volume_trim, Gran_trim)\n",
    "\n",
    "# solve for the x-intercept (where y = 0)\n",
    "\n",
    "x_intercept = \n",
    "\n",
    "print (\"The 1st equivalence point determined by the Gran plot is \" + str(x_intercept) + \" mL\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record this endpoint in your ELN, too.  How different is this value from the 1st equivalence point determined by the derivative method?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "\n",
    "Attach this completed Jupyter notebook file to your Results and Analysis page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
