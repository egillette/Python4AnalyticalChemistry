{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing a chromatogram\n",
    "\n",
    "In lecture on April 17, we saw how we need to extract certain parameters from any chromatogram:  peak retention times, mobile phase times, peak areas, and peak widths.  Now, you have generated an optimized separation for a sample containing 10 different analytes and exported the resulting virtual chromatogram.  Let's see how we can use Python to process this chromatogram.   \n",
    "\n",
    "Your coding today can be done using tools that you have already learned so far this semester -- the only new syntax Dr. D needs to introduce today is \"if ... and ... :\" statements, where two things have to be true, and some code to add a column of zeros to a 2-D array.  As a result, Dr. D will be providing less sample code, so that you can be creative and step out on your own.  This should be more fun and an intense learning experience!\n",
    "\n",
    "So, first, a crucial bit of planning.  Answer the following questions <i>in a detailed way</i> to create a plan for your coding.\n",
    "\n",
    "1. How could you have Python distinguish between peaks and baseline in a chromatogram file (signal vs time)?\n",
    "\n",
    "2. How could you have Python locate the <i>beginning</i> of a chromatographic peak (where it leaves the baseline)?\n",
    "\n",
    "3. How could you have Python locate the <i>end</i> of a chromatographic peak?\n",
    "\n",
    "4. Once you have the beginning and end of a peak located, how could Python calculate the <i>peak area</i>?\n",
    "\n",
    "5. Once you have the beginning and end of a peak located, what numpy function could you use to locate the peak's <i>retention time</i>?\n",
    "\n",
    "6. Once you have the beginning and end of a peak located, how could you use Python to calculate the <i>peak width</i> (at the base of the peak)?\n",
    "\n",
    "### Upload your group's best separation\n",
    "\n",
    "Once you've created a plan, your first step of coding will be to upload the comma delimited values (.csv) export file (either ACN or MeOH, whichever gave your group the best overall separation).  Then, you'll execute your plan in order from simplest to more complex coding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages into Python, as usual.  We'll for sure need these two:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Next, read in the .csv datafile that you just made.\n",
    "\n",
    "# print out the data to check on its format.  Are all the numbers where you think they are?  Did you get all the data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake zeros or \"nan\"s?\n",
    "Did you remove the column headers from your .csv file?  If so, your time data should start with zero, and your signal data may contain baseline zeros.  These zeros are OK.  But if you have fake zeros or \"nan\"s in your file, you can either remove them now with code using the block below, or re-import a .csv file with the text removed.  If your data is OK as is, skip to the next block.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example function that removes \"nan\" values from a numpy array called x.\n",
    "# x = x[np.logical_not(np.isnan(x))]\n",
    "\n",
    "# Here is an example function that removes zeros from a numpy array called x.\n",
    "# x = np.trim_zeros(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your data for posterity\n",
    "\n",
    "You already know what your chromatogram looks like, because the HPLC simulator shows it to you.  But you'd like a copy for your ELN.  Use your Python skills to slice out the time and signal data from your array, and your Python plotting skills to create and save a chromatogram plot from the imported .csv data.  Let's draw it with a blue line and no data point symbols, just like the simulator did.  Don't forget axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste and adapt code here.\n",
    "# Slicing\n",
    "\n",
    "\n",
    "\n",
    "# Plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a 3rd column to your array\n",
    "\n",
    "The slicing was just to make a graph.  Now we'll go back to working with the 2-D array.  \n",
    "By adding a 3rd column, you are making a place for \"marker\" data, which will designate what is a peak and what is baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example append column function that adds a new column of zeros to a 2-D array called \"a\".  The result is\n",
    "# a new array called \"b\":\n",
    "# b = numpy.append(a,np.zeros([len(a),1]),1)\n",
    "\n",
    "\n",
    "# Now write a print statement to make sure it worked correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguishing chromatographic peaks from baseline\n",
    "\n",
    "Now it's time to execute your strategy for distinguishing peaks from baseline.  When there is a peak, have Python put a \"1\" in the 3rd column.  When there is baseline, leave a zero in the 3rd column.  Go for it in the code block below, and then check your work with a print statement!\n",
    "\n",
    "\n",
    "(If you are feeling lost, however, here is my suggestion:  write a FOR loop that looks through the dataset at the values in the signal column (\"filename[i,1]\").  Within that loop, IF the signal is > 1 (or some other threshold), a peak is eluting, and you should record a \"1\" in the third column at this point (\"filename[i,2] = 1\").  After the loop is finished, you should have \"1's\" whenever the signal is greater than the threshold (a peak) and \"0's\" whenever the signal is less than the threshold (baseline).  These 1's and 0's function as markers (or a \"mask\") to distinguish peaks from baseline.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste and adapt code here.  Or, to show off, write something from scratch.\n",
    "\n",
    "\n",
    "\n",
    "# Print out your result.  Did it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration\n",
    "Can you think up a way to integrate all the peaks together, but not any of the baseline, making use of your marker column?  Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?  Nice!\n",
    "\n",
    "Obviously, you'd like to integrate each peak individually, but integrating the whole file was good practice. \n",
    "\n",
    "## Locating peak starting and ending times\n",
    "Now it's time for you to execute your strategies 2 and 3.  You are free to do this however you like, but once your code is working, <b>you must provide comments in your code explaining what is happening</b>.  This is a challenging coding exercise, so I'll provide a few suggestions below, which you can use if you find them helpful.  \n",
    "\n",
    "\n",
    "As you create code to find peak starting and ending points, you'll need a way to store this information.  You'll find it convenient to create a new output array (\"peakdata\") for recording peak information, <i>with each row corresponding to one peak</i>.  You could, for example, use the first column to store the time that a peak begins, and the second column for the time that the peak ends.  (We'll add other columns later.)  You can decide what your output data structure should be, but be sure to explain it with comments.  \n",
    "\n",
    "\n",
    "(If you are feeling lost, here is a more detailed suggested strategy:  Use IF statements to find the beginning and ending of each peak, nested within a FOR loop that walks row by row through the main data array.  I used \"if filename[i,2] == 0 and filename[(i+1),2] == 1\" syntax to locate the start of each peak using the marker column, then wrote the start time (from line i+1) to a temporary variable.  A second IF ... AND locates the end of the peak, records the end time to another temporary variable, and then writes both temporary variables to a temporary array.  Finally, the temporary array gets appended to the output array, a strategy identical to how you built that lnk vs phi 2-D array last week!  So, all of these individual steps are things you've done before.)\n",
    "\n",
    "### Syntax note  \n",
    "In Python, the double equal sign (\"==\") is used when you are checking if two things are equal (If x == 3: # 'If condition is true, then do the following ...').  The single equal sign is used for setting the term on the left to be the same as the term on the right (x = 3   # 'Set variable x to be 3').  Almost every computer language makes a syntax distinction between these two meanings of 'equal'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare peakdata as an empty array.\n",
    "\n",
    "\n",
    "# Code to identify peak starting and ending times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the number of rows in your output array the same as the number of peaks in the chromatogram?  If not, you might need to adjust the threshold value to make sure that it is slightly larger than the height of the valley between the two closest peaks -- this means two peaks weren't quite baseline resolved.  We won't worry about that -- let's just make the code work!\n",
    "\n",
    "Once you have the previous code block working to identify all peak starting and ending times, you should feel very proud of your work!  \n",
    "Wow!  Companies charge a lot for chromatography software, and you just made some yourself!  \n",
    "\n",
    "Copy your code into the code block below, because it is easiest to adapt it to also ...\n",
    "\n",
    "\n",
    "## Integrate individual peaks\n",
    "Time to execute your strategy 4!  Again, do this according to your strategy, and add comments once the code is working.  \n",
    "\n",
    "Optional hints:  \n",
    "Have the code recreate the output array from scratch, redefining it as empty at the start.  \n",
    "In between your IF statements that find the start and end of the peak, insert another IF statement that integrates the peak when the marker in column 3 is 1.  (You are essentially re-using your FOR loop for further purposes.)\n",
    "\n",
    "Be sure that the integration temporary variable gets reset to zero <i>before</i> you start integrating each peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the top of each peak (retention times)\n",
    "We know how to find the largest number in an entire array using the np.argmax(filename) function, but how do we find the largest number in a subset of data (for one particular peak)?  As usual, there are a few ways that this can be done, some of which are listed below.  Implement the strategy of your choice, modifying a copy of your previous code block again!\n",
    "\n",
    "One way to numerically find the largest number in a set is to have Python move through the set of signal numbers for in individual peak, asking \"Is the next number larger than the current number?  If so, take the next number (and its associated retention time).  If not, stick with the current number.\"  You could do this parallel to the integration in your code, inside the same IF statement.  When the peak ends, you should end up with the highest signal and the peak retention time, which could be added to the output array.\n",
    "\n",
    "Another option is to take the signal data and time data for an individual peak, and, parallel to the integration code, append these two datasets (one number at a time) into temporary arrays.  Once the peak is over (IF statement 3), you could use the np.argmax function to return the index of the largest number in the signal array.  The index can then be used to find the matching number in the time array, just like we did in PythonLab 1 when we were looking for titration endpoints.  The retention time would get added to the output array, and the temporary arrays would be set to zero to prepare for the analysis of the next peak.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating peak widths\n",
    "Next, we want to get Python to estimate peak widths.  Since we already have the start and end times of each peak, this should be relatively easy!  \n",
    "\n",
    "Keep in mind that since we are not using a <i>triangle approximation</i> to measure the peak width at the base of the peak, your peak widths based on the starting and end times of a peak will be larger than the official definition of peak width $W$.  However, you can convert peak widths based on starting and end times of a peak to $W_{1/2}$ using the following approximation:  $$ W_{1/2} = 0.38*W_{end-start} $$ \n",
    "\n",
    "Use your strategy 6 in the code block below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will also calculate peak widths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating resolution between neighboring peaks\n",
    "Last week, we calculated relative retention factors between neighboring peaks, which doesn't take peak width into account.  Now, we've got peak widths, so at last we can calculate resolution!  Remember that the equation for resolution is $$R = \\frac{0.589 * \\Delta t_{r}}{average W_{1/2}} $$\n",
    "\n",
    "Keep adapting your code to add in this last calculation to the appropriate IF statement.  Your output array will now have 6 columns.  We'll calculate the resolution of each peak with the peak to its left.  \n",
    "\n",
    "HINTS:  before calculating peak width for the current peak, save the peak width calculated for the previous peak into a \"peakwidthprevious\" variable.  Then you can use the current peak width and the previous peak width to calculate $W_{1/2 average}$.   Similarly, before the calculation of the retention time of the current peak, you can save the retention time calculated for the previous peak into a \"trprevious\" variable.  Then, you can use the current and previous peak's retention times to calculate $\\Delta t_{r}$.\n",
    "Since we are calculating resolution for a peak and the peak on its left, the first peak to elute will not have a valid resolution.  You can ignore this first resolution value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will also calculate resolution between each peak and the peak to its left.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa!  You've created some useful chromatography code, and greatly expanded your coding skills.  Great work!\n",
    "\n",
    "### Displaying your output array  \n",
    "Use Python to create a table of your output array data -- with integration start times, integration end times, retention times, areas, W_1/2 values, and resolution for each peak, in labelled columns with units.  (No brackets, if possible.)  Once you get something that looks decent, snap a screenshot for your ELN.\n",
    "\n",
    "(Hint:  you can use a separate print statement to provide the column labels and units!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, you made it!  Almost time to crack a well-deserved cold one!\n",
    "\n",
    "\n",
    "## Submission Instructions\n",
    "In your ELN, upload the chromatogram you made in this notebook, and a screenshot of your final output array table, into the Expt 7 R&A section.  Explain what the graph and data table are telling you with a few sentences of narrative.   \n",
    "\n",
    "Save this notebook with your name in the title and upload it, too.  There are a few questions to answer in the ELN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
